{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:17:00.267359Z",
     "iopub.status.busy": "2024-07-18T17:17:00.266973Z",
     "iopub.status.idle": "2024-07-18T17:17:19.692548Z",
     "shell.execute_reply": "2024-07-18T17:17:19.691141Z",
     "shell.execute_reply.started": "2024-07-18T17:17:00.267328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.9.1 in /usr/local/lib/python3.9/dist-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (2.9.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.9.1) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.30.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (3.8.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (15.0.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (66.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.23.4)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.51.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.35.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed protobuf-3.19.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.64.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pydicom in /usr/local/lib/python3.9/dist-packages (2.4.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting protobuf<=3.20.0\n",
      "  Using cached protobuf-3.20.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.9.1\n",
    "!pip install tqdm\n",
    "!pip install pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:16:28.846907Z",
     "iopub.status.busy": "2024-07-18T17:16:28.846367Z",
     "iopub.status.idle": "2024-07-18T17:16:36.608388Z",
     "shell.execute_reply": "2024-07-18T17:16:36.607247Z",
     "shell.execute_reply.started": "2024-07-18T17:16:28.846863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime==1.13.1 in /usr/local/lib/python3.9/dist-packages (1.13.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (1.12)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (1.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (1.13.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (3.20.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (23.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.13.1) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime==1.13.1) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime==1.13.1) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: onnx==1.12.0 in /usr/local/lib/python3.9/dist-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0) (4.4.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0) (3.20.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime==1.13.1\n",
    "!pip install onnx==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:19:52.859689Z",
     "iopub.status.busy": "2024-07-18T17:19:52.858733Z",
     "iopub.status.idle": "2024-07-18T17:19:56.983776Z",
     "shell.execute_reply": "2024-07-18T17:19:56.982292Z",
     "shell.execute_reply.started": "2024-07-18T17:19:52.859660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in /usr/local/lib/python3.9/dist-packages (from tf2onnx) (1.12)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from tf2onnx) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.9/dist-packages (from tf2onnx) (1.23.4)\n",
      "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from tf2onnx) (1.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from tf2onnx) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx>=1.4.1->tf2onnx) (4.4.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from onnx>=1.4.1->tf2onnx) (3.19.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->tf2onnx) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->tf2onnx) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->tf2onnx) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->tf2onnx) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:18:55.664890Z",
     "iopub.status.busy": "2024-07-18T17:18:55.664425Z",
     "iopub.status.idle": "2024-07-18T17:19:00.953297Z",
     "shell.execute_reply": "2024-07-18T17:19:00.952418Z",
     "shell.execute_reply.started": "2024-07-18T17:18:55.664849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf<3.20.0\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.0\n",
      "    Uninstalling protobuf-3.20.0:\n",
      "      Successfully uninstalled protobuf-3.20.0\n",
      "Successfully installed protobuf-3.19.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install 'protobuf < 3.20.0' --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:09:45.862785Z",
     "iopub.status.busy": "2024-07-18T17:09:45.861249Z",
     "iopub.status.idle": "2024-07-18T17:09:50.584733Z",
     "shell.execute_reply": "2024-07-18T17:09:50.583151Z",
     "shell.execute_reply.started": "2024-07-18T17:09:45.862736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf<=3.20.0 in /usr/local/lib/python3.9/dist-packages (3.20.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"protobuf<=3.20.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:19:10.897347Z",
     "iopub.status.busy": "2024-07-18T17:19:10.896230Z",
     "iopub.status.idle": "2024-07-18T17:19:14.740842Z",
     "shell.execute_reply": "2024-07-18T17:19:14.739801Z",
     "shell.execute_reply.started": "2024-07-18T17:19:10.897301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: protobuf\n",
      "Version: 3.19.6\n",
      "Summary: Protocol Buffers\n",
      "Home-page: https://developers.google.com/protocol-buffers/\n",
      "Author: \n",
      "Author-email: \n",
      "License: 3-Clause BSD License\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: \n",
      "Required-by: onnx, onnxruntime, tensorboard, tensorflow, wandb\n"
     ]
    }
   ],
   "source": [
    "!pip show protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-18T17:19:16.913863Z",
     "iopub.status.busy": "2024-07-18T17:19:16.912758Z",
     "iopub.status.idle": "2024-07-18T17:19:21.443120Z",
     "shell.execute_reply": "2024-07-18T17:19:21.442075Z",
     "shell.execute_reply.started": "2024-07-18T17:19:16.913786Z"
    },
    "id": "Dm_bKQNaKzty",
    "outputId": "54572967-fee2-4123-eb79-d3ce6016d94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  index                                      DCM_File_Path  \\\n",
      "0              0    531  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Test...   \n",
      "1              1    145  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Test...   \n",
      "2              2    229  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Test...   \n",
      "3              3    419  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Test...   \n",
      "4              4     39  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Test...   \n",
      "...          ...    ...                                                ...   \n",
      "1866        1866    873  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Trai...   \n",
      "1867        1867   1005  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Trai...   \n",
      "1868        1868   1273  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Trai...   \n",
      "1869        1869   3238  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Trai...   \n",
      "1870        1870   2882  D:/chi/DDSM/Mass_train_roi/CBIS-DDSM/Calc-Trai...   \n",
      "\n",
      "      DCM_File_Size                              Label  Number of Images  \\\n",
      "0            133054        Calc-Test_P_00038_LEFT_CC_1                 2   \n",
      "1            133056       Calc-Test_P_00038_LEFT_MLO_1                 2   \n",
      "2            540964       Calc-Test_P_00038_RIGHT_CC_1                 2   \n",
      "3            373220       Calc-Test_P_00038_RIGHT_CC_2                 2   \n",
      "4           1348884      Calc-Test_P_00038_RIGHT_MLO_1                 2   \n",
      "...             ...                                ...               ...   \n",
      "1866        3671660  Calc-Training_P_02566_RIGHT_MLO_1                 2   \n",
      "1867         624254    Calc-Training_P_02572_LEFT_CC_1                 2   \n",
      "1868         639840   Calc-Training_P_02572_LEFT_MLO_1                 2   \n",
      "1869         596746    Calc-Training_P_02584_LEFT_CC_1                 2   \n",
      "1870         563664   Calc-Training_P_02584_LEFT_MLO_1                 2   \n",
      "\n",
      "                                                 Folder Classification  \n",
      "0     \\CBIS-DDSM\\Calc-Test_P_00038_LEFT_CC_1\\08-29-2...         BENIGN  \n",
      "1     \\CBIS-DDSM\\Calc-Test_P_00038_LEFT_MLO_1\\08-29-...         BENIGN  \n",
      "2     \\CBIS-DDSM\\Calc-Test_P_00038_RIGHT_CC_1\\08-29-...         BENIGN  \n",
      "3     \\CBIS-DDSM\\Calc-Test_P_00038_RIGHT_CC_2\\08-29-...         BENIGN  \n",
      "4     \\CBIS-DDSM\\Calc-Test_P_00038_RIGHT_MLO_1\\08-29...         BENIGN  \n",
      "...                                                 ...            ...  \n",
      "1866  \\CBIS-DDSM\\Calc-Training_P_02566_RIGHT_MLO_1\\0...      MALIGNANT  \n",
      "1867  \\CBIS-DDSM\\Calc-Training_P_02572_LEFT_CC_1\\09-...      MALIGNANT  \n",
      "1868  \\CBIS-DDSM\\Calc-Training_P_02572_LEFT_MLO_1\\09...      MALIGNANT  \n",
      "1869  \\CBIS-DDSM\\Calc-Training_P_02584_LEFT_CC_1\\09-...         BENIGN  \n",
      "1870  \\CBIS-DDSM\\Calc-Training_P_02584_LEFT_MLO_1\\09...         BENIGN  \n",
      "\n",
      "[1871 rows x 8 columns]\n",
      "/notebooks/reduced_files_3565/Calc-Test_P_00038_LEFT_CC_1/1-1.dcm\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Setting up Data location\n",
    "##\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import csv\n",
    "import keras\n",
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D\n",
    "from keras.layers import MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "#\n",
    "# Note!! Anything with a path needs to be changed for one's own pc\n",
    "# Changed the \"/notebooks/...\" for reduced_file_path and data = .pd.read_csv your own path\n",
    "# If you are using paperspace this will however always function\n",
    "#\n",
    "data = pd.read_csv(\"/notebooks/DCM_File_Paths_Reduced.csv\")\n",
    "\n",
    "size_list_dir = []\n",
    "finalized_list_dir = []\n",
    "\n",
    "#Will be used for comparsion to find the ROI dcm files\n",
    "Label_list = []\n",
    "#Number of Images\n",
    "Number_of_Images=[]\n",
    "Pathology=[]\n",
    "folder = []\n",
    "#The counter is used to align the labels and the File Location together\n",
    "counter = 0;\n",
    "\n",
    "#Checker is to test the individual file location and how does it look as a str\n",
    "checker = ''\n",
    "data=data.sort_values('DCM_File_Path')\n",
    "\n",
    "#\n",
    "# The \"data\" variable selects either the Mass or Calc dataset\n",
    "# \n",
    "print(data[data['Label'].str.contains(\"Calc\")]) #Checking if it works\n",
    "data = data[data['Label'].str.contains(\"Calc\")] #Filtered for just Calc\n",
    "#data = data[data['Label'].str.contains(\"Mass\")] #Can pick Mass instead, comment Calc\n",
    "##\n",
    "## Note!! If used on one's own pc, change reduced_file_path\n",
    "##\n",
    "reduced_file_path =  '/notebooks/reduced_files_3565/'\n",
    "#Figuring out where to extract data\n",
    "print( reduced_file_path + data['Label'].iloc[0] +\"/\" + os.listdir(reduced_file_path + data['Label'].iloc[0])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-18T17:21:12.343773Z",
     "iopub.status.busy": "2024-07-18T17:21:12.342953Z",
     "iopub.status.idle": "2024-07-18T17:21:31.828454Z",
     "shell.execute_reply": "2024-07-18T17:21:31.827019Z",
     "shell.execute_reply.started": "2024-07-18T17:21:12.343712Z"
    },
    "id": "o_VJHfs7Tugq",
    "outputId": "26d9a3cb-26dd-440f-eeaf-280a0caf995f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1871 [00:00<?, ?it/s]/tmp/ipykernel_326/148019414.py:71: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img_resize = img.resize((h,w), Image.LANCZOS)\n",
      "100%|██████████| 1871/1871 [00:19<00:00, 96.45it/s] \n"
     ]
    }
   ],
   "source": [
    "    # \n",
    "    # Data Processing\n",
    "    #\n",
    "    import numpy as np\n",
    "    import keras\n",
    "    from keras.models import Model, Sequential\n",
    "    from keras.layers import Input, Dense, Conv2D\n",
    "    from keras.layers import MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "    from tensorflow.keras.models import Model, Sequential\n",
    "    import keras\n",
    "    from keras.models import Model, Sequential\n",
    "    from keras.layers import Input, Dense, Conv2D, BatchNormalization, LeakyReLU\n",
    "    from keras.layers import MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "    #from keras.preprocessing.image import load_img, img_to_array\n",
    "    from tensorflow.keras.regularizers import l1\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import pydicom        # install the pydicom package\n",
    "    from PIL import Image # install the pillow package and it is called PIL.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    from matplotlib import pyplot\n",
    "    # train autoencoder for classification with no compoutputression in the bottleneck layer\n",
    "    import keras\n",
    "    from keras import layers\n",
    "    # train autoencoder for classification with no compression in the bottleneck layer\n",
    "    import keras\n",
    "    from keras import layers\n",
    "    h = 299\n",
    "    w = 299\n",
    "    ch = 1\n",
    "\n",
    "\n",
    "\n",
    "    #This is the example code that tests out dcms\n",
    "    #Using the finalized_list_dir I can use my locations\n",
    "    #This also means of course I can loop them, show the labels of each of them,etc\n",
    "\n",
    "    trigger = 0\n",
    "    counter = 0\n",
    "    dcmMask = np.zeros((len(data),h,w,1), dtype=\"float\")\n",
    "    y_label = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(0,len(data))):\n",
    "        #Setting up x and y\n",
    "        dicomdata = pydicom.read_file(reduced_file_path + data['Label'].iloc[i]\n",
    "                                      + \"/\" + os.listdir(reduced_file_path + data['Label'].iloc[i])[0],force=True)  # masked image\n",
    "        if data['Classification'].iloc[i]  == 'BENIGN':\n",
    "            y_label.append(1)\n",
    "        else:\n",
    "            y_label.append(0)\n",
    "\n",
    "        #Testing if labels and dcm align properly\n",
    "        #if trigger < 5:\n",
    "        #    print('This is class ',i+20,edited_df['Classification'].iloc[i+20])\n",
    "        #    print('This is path ', i+20,edited_df['DCM_File_Path'].iloc[i+20])\n",
    "        #    trigger+=1\n",
    "        #Converting to numpy array\n",
    "        tmp = np.zeros((dicomdata.Rows, dicomdata.Columns), dtype=\"float32\")\n",
    "        tmp = dicomdata.pixel_array/65535.0\n",
    "\n",
    "        img = Image.fromarray(tmp)\n",
    "        img_resize = img.resize((h,w), Image.LANCZOS)\n",
    "        tmp2 = img_to_array(img_resize)\n",
    "        dcmMask[i] = tmp2.reshape((h,w,ch))\n",
    "        #Testing if data is set up as a 3d Rensor\n",
    "        \"\"\"\n",
    "        if trigger != 10:\n",
    "            print('this is dimension',dcmMask[i].ndim)\n",
    "            print('this is shape',dcmMask[i].shape)\n",
    "            print('this is type',dcmMask[i].dtype)\n",
    "            print('this looks like this', dcmMask[i])\n",
    "            print('this is path:',reduced_file_path + data['Label'].iloc[i]\n",
    "                                      + \"/\" + os.listdir('/content/drive/MyDrive/reduced_files/' + data['Label'].iloc[i])[0])\n",
    "            print('this is path classification:',data['Classification'].iloc[i])\n",
    "            trigger+=1\n",
    "        \"\"\"\n",
    "        #If you are interested to see all the pictures individually,increased runtime\n",
    "        #data = tmp2.reshape((h,w,ch))\n",
    "        #plt.imshow(np.reshape(data, (h, w)), cmap='gray')\n",
    "        #plt.show()\n",
    "    #print(dcmMask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:14:17.222530Z",
     "iopub.status.busy": "2024-07-18T17:14:17.221671Z",
     "iopub.status.idle": "2024-07-18T17:14:17.227607Z",
     "shell.execute_reply": "2024-07-18T17:14:17.226591Z",
     "shell.execute_reply.started": "2024-07-18T17:14:17.222499Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3696076252.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T16:45:13.110122Z",
     "iopub.status.busy": "2024-07-18T16:45:13.108706Z",
     "iopub.status.idle": "2024-07-18T16:45:15.375546Z",
     "shell.execute_reply": "2024-07-18T16:45:15.374566Z",
     "shell.execute_reply.started": "2024-07-18T16:45:13.110078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading resnet50 to local path /root/.cache/onnx/hub/validated/vision/classification/resnet/model/af16a04a6ec48ac494065d4439fe9dea590d337b9ca6dc328160ccf04a217b9c_resnet50-v1-7.onnx\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Will experiment with onnx models later\n",
    "#\n",
    "from onnx import hub\n",
    "model = hub.load(\"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:20:47.708971Z",
     "iopub.status.busy": "2024-07-18T17:20:47.707583Z",
     "iopub.status.idle": "2024-07-18T17:20:59.603871Z",
     "shell.execute_reply": "2024-07-18T17:20:59.602114Z",
     "shell.execute_reply.started": "2024-07-18T17:20:47.708894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219055592/219055592 [==============================] - 2s 0us/step\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 299, 299, 3)  0           ['input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 96)   18432       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 64)   12288       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 64)  192         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed_5b (Concatenate)         (None, 35, 35, 320)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 32)  96          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 32)  96          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 48)  144         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 32)  96          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 32)  96          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 64)  192         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " block35_1_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " block35_1_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_1_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_1 (Lambda)             (None, 35, 35, 320)  0           ['mixed_5b[0][0]',               \n",
      "                                                                  'block35_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_1_ac (Activation)      (None, 35, 35, 320)  0           ['block35_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 32)  96          ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 32)  96          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 48)  144         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 32)  96          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 32)  96          ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 64)  192         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " block35_2_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_18[0][0]',          \n",
      "                                                                  'activation_20[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " block35_2_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_2_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_2 (Lambda)             (None, 35, 35, 320)  0           ['block35_1_ac[0][0]',           \n",
      "                                                                  'block35_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_2_ac (Activation)      (None, 35, 35, 320)  0           ['block35_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 32)  96          ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 32)  96          ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 48)  144         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 32)  96          ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 35, 35, 32)  96          ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 35, 35, 64)  192         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " block35_3_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_24[0][0]',          \n",
      "                                                                  'activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " block35_3_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_3_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_3 (Lambda)             (None, 35, 35, 320)  0           ['block35_2_ac[0][0]',           \n",
      "                                                                  'block35_3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_3_ac (Activation)      (None, 35, 35, 320)  0           ['block35_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 35, 35, 32)  96          ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 35, 35, 32)  96          ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 35, 35, 48)  144         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 35, 35, 32)  96          ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 35, 35, 32)  96          ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 35, 35, 64)  192         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " block35_4_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_32[0][0]',          \n",
      "                                                                  'activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " block35_4_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_4_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_4 (Lambda)             (None, 35, 35, 320)  0           ['block35_3_ac[0][0]',           \n",
      "                                                                  'block35_4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_4_ac (Activation)      (None, 35, 35, 320)  0           ['block35_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 35, 35, 32)  96          ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 35, 35, 32)  96          ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 35, 35, 48)  144         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 35, 35, 32)  96          ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 35, 35, 32)  96          ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 35, 35, 64)  192         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " block35_5_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_36[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " block35_5_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_5_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_5 (Lambda)             (None, 35, 35, 320)  0           ['block35_4_ac[0][0]',           \n",
      "                                                                  'block35_5_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_5_ac (Activation)      (None, 35, 35, 320)  0           ['block35_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 35, 35, 32)  96          ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 35, 35, 32)  96          ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 35, 35, 48)  144         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 35, 35, 32)  96          ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 35, 35, 32)  96          ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 35, 35, 64)  192         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " block35_6_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_42[0][0]',          \n",
      "                                                                  'activation_44[0][0]',          \n",
      "                                                                  'activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " block35_6_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_6_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_6 (Lambda)             (None, 35, 35, 320)  0           ['block35_5_ac[0][0]',           \n",
      "                                                                  'block35_6_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_6_ac (Activation)      (None, 35, 35, 320)  0           ['block35_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 35, 35, 32)  96          ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 35, 35, 32)  96          ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 35, 35, 48)  144         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 35, 35, 32)  96          ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 35, 35, 32)  96          ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 35, 35, 64)  192         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " block35_7_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_48[0][0]',          \n",
      "                                                                  'activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " block35_7_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_7_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_7 (Lambda)             (None, 35, 35, 320)  0           ['block35_6_ac[0][0]',           \n",
      "                                                                  'block35_7_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_7_ac (Activation)      (None, 35, 35, 320)  0           ['block35_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 35, 35, 32)  96          ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 35, 35, 32)  96          ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 35, 35, 48)  144         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 35, 35, 32)  96          ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 35, 35, 32)  96          ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 35, 35, 64)  192         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " block35_8_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_54[0][0]',          \n",
      "                                                                  'activation_56[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " block35_8_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_8_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_8 (Lambda)             (None, 35, 35, 320)  0           ['block35_7_ac[0][0]',           \n",
      "                                                                  'block35_8_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_8_ac (Activation)      (None, 35, 35, 320)  0           ['block35_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 35, 35, 32)  96          ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 35, 35, 32)  96          ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 35, 35, 48)  144         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 35, 35, 32)  96          ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 35, 35, 32)  96          ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 35, 35, 64)  192         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " block35_9_mixed (Concatenate)  (None, 35, 35, 128)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_62[0][0]',          \n",
      "                                                                  'activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " block35_9_conv (Conv2D)        (None, 35, 35, 320)  41280       ['block35_9_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_9 (Lambda)             (None, 35, 35, 320)  0           ['block35_8_ac[0][0]',           \n",
      "                                                                  'block35_9_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_9_ac (Activation)      (None, 35, 35, 320)  0           ['block35_9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 35, 35, 32)  96          ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 35, 35, 48)   13824       ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 35, 35, 32)  96          ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 35, 35, 48)  144         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 35, 35, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 35, 35, 32)   9216        ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 35, 35, 64)   27648       ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 35, 35, 32)  96          ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 35, 35, 32)  96          ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 35, 35, 64)  192         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0          ['activation_66[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " block35_10_conv (Conv2D)       (None, 35, 35, 320)  41280       ['block35_10_mixed[0][0]']       \n",
      "                                                                                                  \n",
      " block35_10 (Lambda)            (None, 35, 35, 320)  0           ['block35_9_ac[0][0]',           \n",
      "                                                                  'block35_10_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block35_10_ac (Activation)     (None, 35, 35, 320)  0           ['block35_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 35, 35, 256)  81920       ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 35, 35, 256)  768        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 35, 35, 256)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 35, 35, 256)  589824      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 35, 35, 256)  768        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 35, 35, 256)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 384)  1105920     ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 17, 17, 384)  884736      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0          ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " mixed_6a (Concatenate)         (None, 17, 17, 1088  0           ['activation_72[0][0]',          \n",
      "                                )                                 'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 17, 17, 128)  139264      ['mixed_6a[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 17, 17, 128)  384        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 17, 17, 160)  480        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 17, 17, 192)  208896      ['mixed_6a[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 17, 17, 192)  576        ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 17, 17, 192)  576        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " block17_1_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_76[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " block17_1_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_1_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_1 (Lambda)             (None, 17, 17, 1088  0           ['mixed_6a[0][0]',               \n",
      "                                )                                 'block17_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_1_ac (Activation)      (None, 17, 17, 1088  0           ['block17_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 17, 17, 128)  139264      ['block17_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 17, 17, 128)  384        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 17, 17, 160)  480        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 17, 17, 192)  208896      ['block17_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 17, 17, 192)  576        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 17, 17, 192)  576        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " block17_2_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_80[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " block17_2_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_2_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_2 (Lambda)             (None, 17, 17, 1088  0           ['block17_1_ac[0][0]',           \n",
      "                                )                                 'block17_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_2_ac (Activation)      (None, 17, 17, 1088  0           ['block17_2[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 17, 17, 128)  139264      ['block17_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 17, 17, 128)  384        ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 17, 17, 160)  480        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 17, 17, 192)  208896      ['block17_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 17, 17, 192)  576        ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 17, 17, 192)  576        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " block17_3_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_84[0][0]',          \n",
      "                                                                  'activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " block17_3_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_3_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_3 (Lambda)             (None, 17, 17, 1088  0           ['block17_2_ac[0][0]',           \n",
      "                                )                                 'block17_3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_3_ac (Activation)      (None, 17, 17, 1088  0           ['block17_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 17, 17, 128)  139264      ['block17_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 17, 17, 128)  384        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 17, 17, 160)  480        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 17, 17, 192)  208896      ['block17_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 17, 17, 192)  576        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 17, 17, 192)  576        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " block17_4_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_88[0][0]',          \n",
      "                                                                  'activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " block17_4_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_4_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_4 (Lambda)             (None, 17, 17, 1088  0           ['block17_3_ac[0][0]',           \n",
      "                                )                                 'block17_4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_4_ac (Activation)      (None, 17, 17, 1088  0           ['block17_4[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 17, 17, 128)  139264      ['block17_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 17, 17, 128)  384        ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 17, 17, 160)  480        ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 17, 17, 192)  208896      ['block17_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 17, 17, 192)  576        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 17, 17, 192)  576        ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " block17_5_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_92[0][0]',          \n",
      "                                                                  'activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " block17_5_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_5_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_5 (Lambda)             (None, 17, 17, 1088  0           ['block17_4_ac[0][0]',           \n",
      "                                )                                 'block17_5_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_5_ac (Activation)      (None, 17, 17, 1088  0           ['block17_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 17, 17, 128)  139264      ['block17_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 17, 17, 128)  384        ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 17, 17, 160)  143360      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 17, 17, 160)  480        ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 17, 17, 192)  208896      ['block17_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 17, 17, 192)  576        ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 17, 17, 192)  576        ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " block17_6_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_96[0][0]',          \n",
      "                                                                  'activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " block17_6_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_6_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_6 (Lambda)             (None, 17, 17, 1088  0           ['block17_5_ac[0][0]',           \n",
      "                                )                                 'block17_6_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_6_ac (Activation)      (None, 17, 17, 1088  0           ['block17_6[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 17, 17, 128)  139264      ['block17_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 17, 17, 128)  384        ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 17, 17, 160)  143360      ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 17, 17, 160)  480        ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 17, 17, 192)  208896      ['block17_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 17, 17, 192)  576        ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 17, 17, 192)  576        ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " block17_7_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_100[0][0]',         \n",
      "                                                                  'activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " block17_7_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_7_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_7 (Lambda)             (None, 17, 17, 1088  0           ['block17_6_ac[0][0]',           \n",
      "                                )                                 'block17_7_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_7_ac (Activation)      (None, 17, 17, 1088  0           ['block17_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 17, 17, 128)  139264      ['block17_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 17, 17, 128)  384        ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 17, 17, 160)  143360      ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 17, 17, 160)  480        ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 17, 17, 192)  208896      ['block17_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 17, 17, 192)  576        ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 17, 17, 192)  576        ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " block17_8_mixed (Concatenate)  (None, 17, 17, 384)  0           ['activation_104[0][0]',         \n",
      "                                                                  'activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " block17_8_conv (Conv2D)        (None, 17, 17, 1088  418880      ['block17_8_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_8 (Lambda)             (None, 17, 17, 1088  0           ['block17_7_ac[0][0]',           \n",
      "                                )                                 'block17_8_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_8_ac (Activation)      (None, 17, 17, 1088  0           ['block17_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,361,888\n",
      "Trainable params: 12,020,848\n",
      "Non-trainable params: 1,341,040\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ResNet Set up\n",
    "#\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2,EfficientNetB1,EfficientNetB2,InceptionResNetV2 \t\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Concatenate, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "#\n",
    "# Onnx Testing\n",
    "#\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "# Define the input shape for grayscale images\n",
    "input_shape = (299, 299, 1)\n",
    "\n",
    "# Create an input layer for grayscale images\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Repeat the single-channel input to create a 3-channel input\n",
    "rgb_input = Concatenate()([input_layer, input_layer, input_layer])\n",
    "\n",
    "# Load the InceptionResNetV2 model with modified input\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=rgb_input)\n",
    "\n",
    "for layer in base_model.layers[:200]:\n",
    "   layer.trainable = False\n",
    "for layer in base_model.layers[200:]:\n",
    "   layer.trainable = True\n",
    "# Remove top layers (classification layers)\n",
    "ResNet_features = base_model.get_layer('block17_8_ac').output\n",
    "\n",
    "flaten = Dense(latent_dim, name='log_sigma')(Flatten()(ResNet_features))\n",
    "# Model Construction\n",
    "ResNet_Model = Model(input_layer, ResNet_features, name=\"encoder_model\")\n",
    "ResNet_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:21:31.830472Z",
     "iopub.status.busy": "2024-07-18T17:21:31.830187Z",
     "iopub.status.idle": "2024-07-18T17:21:33.577692Z",
     "shell.execute_reply": "2024-07-18T17:21:33.576610Z",
     "shell.execute_reply.started": "2024-07-18T17:21:31.830447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is length of array:  3742\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Data augmentation\n",
    "#\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Details of augmetation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# Variables of augmentation\n",
    "\n",
    "train_gen = datagen.flow(dcmMask,y_label,batch_size=1)\n",
    "combinedImages = np.vstack((dcmMask,train_gen.x))\n",
    "combinedYlabel = np.concatenate((y_label, train_gen.y), axis=0)\n",
    "#\n",
    "print('This is length of array: ',len(combinedYlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:21:33.579324Z",
     "iopub.status.busy": "2024-07-18T17:21:33.579045Z",
     "iopub.status.idle": "2024-07-18T17:21:34.522759Z",
     "shell.execute_reply": "2024-07-18T17:21:34.521528Z",
     "shell.execute_reply.started": "2024-07-18T17:21:33.579299Z"
    },
    "id": "IOtVp6kpd2H2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 299, 299, 1)]     0         \n",
      "                                                                 \n",
      " encoder_model (Functional)  (None, 17, 17, 1088)      13361888  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1088)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1088)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2178      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,364,066\n",
      "Trainable params: 12,023,026\n",
      "Non-trainable params: 1,341,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Classification Set up\n",
    "#\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Dropout\n",
    "#\n",
    "# Classification Set up\n",
    "#\n",
    "ResNet_input = Input(shape=(h,w,ch))\n",
    "ResNet_output = ResNet_Model(ResNet_input)\n",
    "\n",
    "#Classification part\n",
    "x = GlobalAveragePooling2D()(ResNet_output)\n",
    "x = Dropout(0.4)(x) \n",
    "output_classify = Dense(2, activation='softmax')(x)  # Output layer\n",
    "\n",
    "\n",
    "classification_model = Model(inputs=ResNet_input,outputs=output_classify)\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:31:09.293170Z",
     "iopub.status.busy": "2024-07-18T17:31:09.292695Z",
     "iopub.status.idle": "2024-07-18T17:31:27.177367Z",
     "shell.execute_reply": "2024-07-18T17:31:27.176095Z",
     "shell.execute_reply.started": "2024-07-18T17:31:09.293143Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Converting my classification model to onnx\n",
    "#\n",
    "input_signature = [tf.TensorSpec(shape=(None, 299, 299, 1), dtype=tf.float32, name='image_input')]\n",
    "onnx_model, _  = tf2onnx.convert.from_keras(classification_model,input_signature, opset=13)\n",
    "with open(\"my_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:33:41.603395Z",
     "iopub.status.busy": "2024-07-18T17:33:41.603043Z",
     "iopub.status.idle": "2024-07-18T17:33:41.861439Z",
     "shell.execute_reply": "2024-07-18T17:33:41.860314Z",
     "shell.execute_reply.started": "2024-07-18T17:33:41.603368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph tf2onnx (\n",
      "  %image_input[FLOAT, unk__5453x299x299x1]\n",
      ") initializers (\n",
      "  %model/encoder_model/conv2d_99/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_99/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_98/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_98/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_97/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_97/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_96/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_96/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_95/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_95/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_94/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_94/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_93/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_93/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_92/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_92/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_91/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_91/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_90/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_90/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_9/Conv2D_weights_fused_bn[FLOAT, 96x64x3x3]\n",
      "  %model/encoder_model/conv2d_9/Conv2D_bias_fused_bn[FLOAT, 96]\n",
      "  %model/encoder_model/conv2d_89/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_89/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_88/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_88/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_87/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_87/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_86/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_86/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_85/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_85/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_84/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_84/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_83/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_83/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_82/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_82/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_81/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_81/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_80/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_80/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_8/Conv2D_weights_fused_bn[FLOAT, 64x192x1x1]\n",
      "  %model/encoder_model/conv2d_8/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_79/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_79/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_78/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_78/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_77/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_77/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_76/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_76/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_75/Conv2D_weights_fused_bn[FLOAT, 384x256x3x3]\n",
      "  %model/encoder_model/conv2d_75/Conv2D_bias_fused_bn[FLOAT, 384]\n",
      "  %model/encoder_model/conv2d_74/Conv2D_weights_fused_bn[FLOAT, 256x256x3x3]\n",
      "  %model/encoder_model/conv2d_74/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %model/encoder_model/conv2d_73/Conv2D_weights_fused_bn[FLOAT, 256x320x1x1]\n",
      "  %model/encoder_model/conv2d_73/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %model/encoder_model/conv2d_72/Conv2D_weights_fused_bn[FLOAT, 384x320x3x3]\n",
      "  %model/encoder_model/conv2d_72/Conv2D_bias_fused_bn[FLOAT, 384]\n",
      "  %model/encoder_model/conv2d_71/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_71/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_70/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_70/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_7/Conv2D_weights_fused_bn[FLOAT, 64x48x5x5]\n",
      "  %model/encoder_model/conv2d_7/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_69/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_69/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_68/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_68/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_67/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_67/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_66/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_66/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_65/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_65/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_64/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_64/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_63/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_63/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_62/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_62/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_61/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_61/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_60/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_60/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_6/Conv2D_weights_fused_bn[FLOAT, 48x192x1x1]\n",
      "  %model/encoder_model/conv2d_6/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_59/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_59/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_58/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_58/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_57/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_57/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_56/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_56/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_55/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_55/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_54/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_54/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_53/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_53/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_52/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_52/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_51/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_51/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_50/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_50/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_5/Conv2D_weights_fused_bn[FLOAT, 96x192x1x1]\n",
      "  %model/encoder_model/conv2d_5/Conv2D_bias_fused_bn[FLOAT, 96]\n",
      "  %model/encoder_model/conv2d_49/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_49/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_48/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_48/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_47/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_47/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_46/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_46/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_45/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_45/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_44/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_44/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_43/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_43/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_42/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_42/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_41/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_41/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_40/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_40/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_4/Conv2D_weights_fused_bn[FLOAT, 192x80x3x3]\n",
      "  %model/encoder_model/conv2d_4/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_39/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_39/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_38/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_38/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_37/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_37/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_36/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_36/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_35/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_35/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_34/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_34/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_33/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_33/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_32/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_32/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_31/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_31/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_30/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_30/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_3/Conv2D_weights_fused_bn[FLOAT, 80x64x1x1]\n",
      "  %model/encoder_model/conv2d_3/Conv2D_bias_fused_bn[FLOAT, 80]\n",
      "  %model/encoder_model/conv2d_29/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_29/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_28/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_28/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_27/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_27/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_26/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_26/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_25/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_25/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_24/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_24/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_23/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_23/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_22/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_22/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_21/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_21/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_20/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_20/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_2/Conv2D_weights_fused_bn[FLOAT, 64x32x3x3]\n",
      "  %model/encoder_model/conv2d_2/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_19/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_19/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_18/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_18/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_17/Conv2D_weights_fused_bn[FLOAT, 64x48x3x3]\n",
      "  %model/encoder_model/conv2d_17/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_16/Conv2D_weights_fused_bn[FLOAT, 48x32x3x3]\n",
      "  %model/encoder_model/conv2d_16/Conv2D_bias_fused_bn[FLOAT, 48]\n",
      "  %model/encoder_model/conv2d_15/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_15/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_14/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_14/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_13/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_13/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_12/Conv2D_weights_fused_bn[FLOAT, 32x320x1x1]\n",
      "  %model/encoder_model/conv2d_12/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d_11/Conv2D_weights_fused_bn[FLOAT, 64x192x1x1]\n",
      "  %model/encoder_model/conv2d_11/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %model/encoder_model/conv2d_107/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_107/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_106/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_106/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_105/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_105/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_104/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_104/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_103/Conv2D_weights_fused_bn[FLOAT, 192x160x7x1]\n",
      "  %model/encoder_model/conv2d_103/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_102/Conv2D_weights_fused_bn[FLOAT, 160x128x1x7]\n",
      "  %model/encoder_model/conv2d_102/Conv2D_bias_fused_bn[FLOAT, 160]\n",
      "  %model/encoder_model/conv2d_101/Conv2D_weights_fused_bn[FLOAT, 128x1088x1x1]\n",
      "  %model/encoder_model/conv2d_101/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %model/encoder_model/conv2d_100/Conv2D_weights_fused_bn[FLOAT, 192x1088x1x1]\n",
      "  %model/encoder_model/conv2d_100/Conv2D_bias_fused_bn[FLOAT, 192]\n",
      "  %model/encoder_model/conv2d_10/Conv2D_weights_fused_bn[FLOAT, 96x96x3x3]\n",
      "  %model/encoder_model/conv2d_10/Conv2D_bias_fused_bn[FLOAT, 96]\n",
      "  %model/encoder_model/conv2d_1/Conv2D_weights_fused_bn[FLOAT, 32x32x3x3]\n",
      "  %model/encoder_model/conv2d_1/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/conv2d/Conv2D_weights_fused_bn[FLOAT, 32x3x3x3]\n",
      "  %model/encoder_model/conv2d/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %model/encoder_model/block35_9_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_9_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_8_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_8_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_7_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_7_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_6_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_6_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_5_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_5_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_5/mul/y:0[FLOAT, scalar]\n",
      "  %model/encoder_model/block35_4_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_4_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_3_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_3_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_2_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_2_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_1_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_1_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block35_10_conv/Conv2D/ReadVariableOp:0[FLOAT, 320x128x1x1]\n",
      "  %model/encoder_model/block35_10_conv/BiasAdd/ReadVariableOp:0[FLOAT, 320]\n",
      "  %model/encoder_model/block17_8_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_8_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_7_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_7_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_6_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_6_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_5_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_5_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_4_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_4_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_3_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_3_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_3/mul/y:0[FLOAT, scalar]\n",
      "  %model/encoder_model/block17_2_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_2_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/encoder_model/block17_1_conv/Conv2D/ReadVariableOp:0[FLOAT, 1088x384x1x1]\n",
      "  %model/encoder_model/block17_1_conv/BiasAdd/ReadVariableOp:0[FLOAT, 1088]\n",
      "  %model/dense/MatMul/ReadVariableOp:0[FLOAT, 1088x2]\n",
      "  %const_axes__5451[INT64, 2]\n",
      ") {\n",
      "  %model/encoder_model/concatenate/concat:0 = Concat[axis = 3](%image_input, %image_input, %image_input)\n",
      "  %model/encoder_model/conv2d/Conv2D__4095:0 = Transpose[perm = [0, 3, 1, 2]](%model/encoder_model/concatenate/concat:0)\n",
      "  %model/encoder_model/batch_normalization/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/conv2d/Conv2D__4095:0, %model/encoder_model/conv2d/Conv2D_weights_fused_bn, %model/encoder_model/conv2d/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation/Relu:0 = Relu(%model/encoder_model/batch_normalization/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_1/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], strides = [1, 1]](%model/encoder_model/activation/Relu:0, %model/encoder_model/conv2d_1/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_1/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_1/Relu:0 = Relu(%model/encoder_model/batch_normalization_1/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_2/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_1/Relu:0, %model/encoder_model/conv2d_2/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_2/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_2/Relu:0 = Relu(%model/encoder_model/batch_normalization_2/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/max_pooling2d/MaxPool:0 = MaxPool[kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/activation_2/Relu:0)\n",
      "  %model/encoder_model/batch_normalization_3/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%model/encoder_model/max_pooling2d/MaxPool:0, %model/encoder_model/conv2d_3/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_3/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_3/Relu:0 = Relu(%model/encoder_model/batch_normalization_3/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_4/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], strides = [1, 1]](%model/encoder_model/activation_3/Relu:0, %model/encoder_model/conv2d_4/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_4/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_4/Relu:0 = Relu(%model/encoder_model/batch_normalization_4/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/max_pooling2d_1/MaxPool:0 = MaxPool[kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/activation_4/Relu:0)\n",
      "  %model/encoder_model/batch_normalization_8/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/max_pooling2d_1/MaxPool:0, %model/encoder_model/conv2d_8/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_8/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_8/Relu:0 = Relu(%model/encoder_model/batch_normalization_8/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_9/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_8/Relu:0, %model/encoder_model/conv2d_9/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_9/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_9/Relu:0 = Relu(%model/encoder_model/batch_normalization_9/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_10/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_9/Relu:0, %model/encoder_model/conv2d_10/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_10/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_10/Relu:0 = Relu(%model/encoder_model/batch_normalization_10/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_6/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/max_pooling2d_1/MaxPool:0, %model/encoder_model/conv2d_6/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_6/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_6/Relu:0 = Relu(%model/encoder_model/batch_normalization_6/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_7/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%model/encoder_model/activation_6/Relu:0, %model/encoder_model/conv2d_7/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_7/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_7/Relu:0 = Relu(%model/encoder_model/batch_normalization_7/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_5/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/max_pooling2d_1/MaxPool:0, %model/encoder_model/conv2d_5/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_5/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_5/Relu:0 = Relu(%model/encoder_model/batch_normalization_5/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/average_pooling2d/AvgPool:0 = AveragePool[kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/max_pooling2d_1/MaxPool:0)\n",
      "  %model/encoder_model/batch_normalization_11/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/average_pooling2d/AvgPool:0, %model/encoder_model/conv2d_11/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_11/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_11/Relu:0 = Relu(%model/encoder_model/batch_normalization_11/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/mixed_5b/concat:0 = Concat[axis = 1](%model/encoder_model/activation_5/Relu:0, %model/encoder_model/activation_7/Relu:0, %model/encoder_model/activation_10/Relu:0, %model/encoder_model/activation_11/Relu:0)\n",
      "  %model/encoder_model/batch_normalization_15/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/mixed_5b/concat:0, %model/encoder_model/conv2d_15/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_15/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_15/Relu:0 = Relu(%model/encoder_model/batch_normalization_15/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_16/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_15/Relu:0, %model/encoder_model/conv2d_16/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_16/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_16/Relu:0 = Relu(%model/encoder_model/batch_normalization_16/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_17/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_16/Relu:0, %model/encoder_model/conv2d_17/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_17/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_17/Relu:0 = Relu(%model/encoder_model/batch_normalization_17/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_13/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/mixed_5b/concat:0, %model/encoder_model/conv2d_13/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_13/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_13/Relu:0 = Relu(%model/encoder_model/batch_normalization_13/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_14/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_13/Relu:0, %model/encoder_model/conv2d_14/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_14/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_14/Relu:0 = Relu(%model/encoder_model/batch_normalization_14/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_12/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/mixed_5b/concat:0, %model/encoder_model/conv2d_12/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_12/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_12/Relu:0 = Relu(%model/encoder_model/batch_normalization_12/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_1_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_12/Relu:0, %model/encoder_model/activation_14/Relu:0, %model/encoder_model/activation_17/Relu:0)\n",
      "  %model/encoder_model/block35_1_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_1_mixed/concat:0, %model/encoder_model/block35_1_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_1_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_1/mul:0 = Mul(%model/encoder_model/block35_1_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_1/add:0 = Add(%model/encoder_model/mixed_5b/concat:0, %model/encoder_model/block35_1/mul:0)\n",
      "  %model/encoder_model/block35_1_ac/Relu:0 = Relu(%model/encoder_model/block35_1/add:0)\n",
      "  %model/encoder_model/batch_normalization_21/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_1_ac/Relu:0, %model/encoder_model/conv2d_21/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_21/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_21/Relu:0 = Relu(%model/encoder_model/batch_normalization_21/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_22/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_21/Relu:0, %model/encoder_model/conv2d_22/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_22/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_22/Relu:0 = Relu(%model/encoder_model/batch_normalization_22/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_23/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_22/Relu:0, %model/encoder_model/conv2d_23/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_23/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_23/Relu:0 = Relu(%model/encoder_model/batch_normalization_23/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_19/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_1_ac/Relu:0, %model/encoder_model/conv2d_19/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_19/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_19/Relu:0 = Relu(%model/encoder_model/batch_normalization_19/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_20/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_19/Relu:0, %model/encoder_model/conv2d_20/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_20/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_20/Relu:0 = Relu(%model/encoder_model/batch_normalization_20/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_18/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_1_ac/Relu:0, %model/encoder_model/conv2d_18/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_18/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_18/Relu:0 = Relu(%model/encoder_model/batch_normalization_18/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_2_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_18/Relu:0, %model/encoder_model/activation_20/Relu:0, %model/encoder_model/activation_23/Relu:0)\n",
      "  %model/encoder_model/block35_2_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_2_mixed/concat:0, %model/encoder_model/block35_2_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_2_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_2/mul:0 = Mul(%model/encoder_model/block35_2_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_2/add:0 = Add(%model/encoder_model/block35_1_ac/Relu:0, %model/encoder_model/block35_2/mul:0)\n",
      "  %model/encoder_model/block35_2_ac/Relu:0 = Relu(%model/encoder_model/block35_2/add:0)\n",
      "  %model/encoder_model/batch_normalization_27/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_2_ac/Relu:0, %model/encoder_model/conv2d_27/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_27/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_27/Relu:0 = Relu(%model/encoder_model/batch_normalization_27/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_28/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_27/Relu:0, %model/encoder_model/conv2d_28/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_28/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_28/Relu:0 = Relu(%model/encoder_model/batch_normalization_28/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_29/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_28/Relu:0, %model/encoder_model/conv2d_29/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_29/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_29/Relu:0 = Relu(%model/encoder_model/batch_normalization_29/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_25/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_2_ac/Relu:0, %model/encoder_model/conv2d_25/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_25/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_25/Relu:0 = Relu(%model/encoder_model/batch_normalization_25/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_26/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_25/Relu:0, %model/encoder_model/conv2d_26/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_26/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_26/Relu:0 = Relu(%model/encoder_model/batch_normalization_26/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_24/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_2_ac/Relu:0, %model/encoder_model/conv2d_24/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_24/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_24/Relu:0 = Relu(%model/encoder_model/batch_normalization_24/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_3_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_24/Relu:0, %model/encoder_model/activation_26/Relu:0, %model/encoder_model/activation_29/Relu:0)\n",
      "  %model/encoder_model/block35_3_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_3_mixed/concat:0, %model/encoder_model/block35_3_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_3_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_3/mul:0 = Mul(%model/encoder_model/block35_3_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_3/add:0 = Add(%model/encoder_model/block35_2_ac/Relu:0, %model/encoder_model/block35_3/mul:0)\n",
      "  %model/encoder_model/block35_3_ac/Relu:0 = Relu(%model/encoder_model/block35_3/add:0)\n",
      "  %model/encoder_model/batch_normalization_33/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_3_ac/Relu:0, %model/encoder_model/conv2d_33/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_33/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_33/Relu:0 = Relu(%model/encoder_model/batch_normalization_33/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_34/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_33/Relu:0, %model/encoder_model/conv2d_34/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_34/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_34/Relu:0 = Relu(%model/encoder_model/batch_normalization_34/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_35/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_34/Relu:0, %model/encoder_model/conv2d_35/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_35/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_35/Relu:0 = Relu(%model/encoder_model/batch_normalization_35/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_31/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_3_ac/Relu:0, %model/encoder_model/conv2d_31/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_31/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_31/Relu:0 = Relu(%model/encoder_model/batch_normalization_31/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_32/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_31/Relu:0, %model/encoder_model/conv2d_32/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_32/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_32/Relu:0 = Relu(%model/encoder_model/batch_normalization_32/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_30/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_3_ac/Relu:0, %model/encoder_model/conv2d_30/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_30/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_30/Relu:0 = Relu(%model/encoder_model/batch_normalization_30/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_4_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_30/Relu:0, %model/encoder_model/activation_32/Relu:0, %model/encoder_model/activation_35/Relu:0)\n",
      "  %model/encoder_model/block35_4_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_4_mixed/concat:0, %model/encoder_model/block35_4_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_4_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_4/mul:0 = Mul(%model/encoder_model/block35_4_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_4/add:0 = Add(%model/encoder_model/block35_3_ac/Relu:0, %model/encoder_model/block35_4/mul:0)\n",
      "  %model/encoder_model/block35_4_ac/Relu:0 = Relu(%model/encoder_model/block35_4/add:0)\n",
      "  %model/encoder_model/batch_normalization_39/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_4_ac/Relu:0, %model/encoder_model/conv2d_39/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_39/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_39/Relu:0 = Relu(%model/encoder_model/batch_normalization_39/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_40/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_39/Relu:0, %model/encoder_model/conv2d_40/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_40/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_40/Relu:0 = Relu(%model/encoder_model/batch_normalization_40/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_41/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_40/Relu:0, %model/encoder_model/conv2d_41/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_41/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_41/Relu:0 = Relu(%model/encoder_model/batch_normalization_41/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_37/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_4_ac/Relu:0, %model/encoder_model/conv2d_37/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_37/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_37/Relu:0 = Relu(%model/encoder_model/batch_normalization_37/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_38/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_37/Relu:0, %model/encoder_model/conv2d_38/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_38/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_38/Relu:0 = Relu(%model/encoder_model/batch_normalization_38/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_36/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_4_ac/Relu:0, %model/encoder_model/conv2d_36/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_36/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_36/Relu:0 = Relu(%model/encoder_model/batch_normalization_36/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_5_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_36/Relu:0, %model/encoder_model/activation_38/Relu:0, %model/encoder_model/activation_41/Relu:0)\n",
      "  %model/encoder_model/block35_5_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_5_mixed/concat:0, %model/encoder_model/block35_5_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_5_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_5/mul:0 = Mul(%model/encoder_model/block35_5_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_5/add:0 = Add(%model/encoder_model/block35_4_ac/Relu:0, %model/encoder_model/block35_5/mul:0)\n",
      "  %model/encoder_model/block35_5_ac/Relu:0 = Relu(%model/encoder_model/block35_5/add:0)\n",
      "  %model/encoder_model/batch_normalization_45/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_5_ac/Relu:0, %model/encoder_model/conv2d_45/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_45/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_45/Relu:0 = Relu(%model/encoder_model/batch_normalization_45/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_46/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_45/Relu:0, %model/encoder_model/conv2d_46/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_46/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_46/Relu:0 = Relu(%model/encoder_model/batch_normalization_46/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_47/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_46/Relu:0, %model/encoder_model/conv2d_47/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_47/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_47/Relu:0 = Relu(%model/encoder_model/batch_normalization_47/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_43/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_5_ac/Relu:0, %model/encoder_model/conv2d_43/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_43/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_43/Relu:0 = Relu(%model/encoder_model/batch_normalization_43/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_44/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_43/Relu:0, %model/encoder_model/conv2d_44/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_44/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_44/Relu:0 = Relu(%model/encoder_model/batch_normalization_44/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_42/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_5_ac/Relu:0, %model/encoder_model/conv2d_42/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_42/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_42/Relu:0 = Relu(%model/encoder_model/batch_normalization_42/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_6_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_42/Relu:0, %model/encoder_model/activation_44/Relu:0, %model/encoder_model/activation_47/Relu:0)\n",
      "  %model/encoder_model/block35_6_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_6_mixed/concat:0, %model/encoder_model/block35_6_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_6_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_6/mul:0 = Mul(%model/encoder_model/block35_6_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_6/add:0 = Add(%model/encoder_model/block35_5_ac/Relu:0, %model/encoder_model/block35_6/mul:0)\n",
      "  %model/encoder_model/block35_6_ac/Relu:0 = Relu(%model/encoder_model/block35_6/add:0)\n",
      "  %model/encoder_model/batch_normalization_51/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_6_ac/Relu:0, %model/encoder_model/conv2d_51/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_51/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_51/Relu:0 = Relu(%model/encoder_model/batch_normalization_51/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_52/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_51/Relu:0, %model/encoder_model/conv2d_52/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_52/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_52/Relu:0 = Relu(%model/encoder_model/batch_normalization_52/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_53/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_52/Relu:0, %model/encoder_model/conv2d_53/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_53/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_53/Relu:0 = Relu(%model/encoder_model/batch_normalization_53/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_49/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_6_ac/Relu:0, %model/encoder_model/conv2d_49/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_49/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_49/Relu:0 = Relu(%model/encoder_model/batch_normalization_49/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_50/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_49/Relu:0, %model/encoder_model/conv2d_50/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_50/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_50/Relu:0 = Relu(%model/encoder_model/batch_normalization_50/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_48/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_6_ac/Relu:0, %model/encoder_model/conv2d_48/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_48/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_48/Relu:0 = Relu(%model/encoder_model/batch_normalization_48/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_7_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_48/Relu:0, %model/encoder_model/activation_50/Relu:0, %model/encoder_model/activation_53/Relu:0)\n",
      "  %model/encoder_model/block35_7_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_7_mixed/concat:0, %model/encoder_model/block35_7_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_7_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_7/mul:0 = Mul(%model/encoder_model/block35_7_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_7/add:0 = Add(%model/encoder_model/block35_6_ac/Relu:0, %model/encoder_model/block35_7/mul:0)\n",
      "  %model/encoder_model/block35_7_ac/Relu:0 = Relu(%model/encoder_model/block35_7/add:0)\n",
      "  %model/encoder_model/batch_normalization_57/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_7_ac/Relu:0, %model/encoder_model/conv2d_57/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_57/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_57/Relu:0 = Relu(%model/encoder_model/batch_normalization_57/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_58/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_57/Relu:0, %model/encoder_model/conv2d_58/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_58/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_58/Relu:0 = Relu(%model/encoder_model/batch_normalization_58/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_59/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_58/Relu:0, %model/encoder_model/conv2d_59/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_59/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_59/Relu:0 = Relu(%model/encoder_model/batch_normalization_59/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_55/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_7_ac/Relu:0, %model/encoder_model/conv2d_55/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_55/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_55/Relu:0 = Relu(%model/encoder_model/batch_normalization_55/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_56/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_55/Relu:0, %model/encoder_model/conv2d_56/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_56/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_56/Relu:0 = Relu(%model/encoder_model/batch_normalization_56/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_54/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_7_ac/Relu:0, %model/encoder_model/conv2d_54/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_54/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_54/Relu:0 = Relu(%model/encoder_model/batch_normalization_54/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_8_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_54/Relu:0, %model/encoder_model/activation_56/Relu:0, %model/encoder_model/activation_59/Relu:0)\n",
      "  %model/encoder_model/block35_8_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_8_mixed/concat:0, %model/encoder_model/block35_8_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_8_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_8/mul:0 = Mul(%model/encoder_model/block35_8_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_8/add:0 = Add(%model/encoder_model/block35_7_ac/Relu:0, %model/encoder_model/block35_8/mul:0)\n",
      "  %model/encoder_model/block35_8_ac/Relu:0 = Relu(%model/encoder_model/block35_8/add:0)\n",
      "  %model/encoder_model/batch_normalization_63/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_8_ac/Relu:0, %model/encoder_model/conv2d_63/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_63/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_63/Relu:0 = Relu(%model/encoder_model/batch_normalization_63/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_64/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_63/Relu:0, %model/encoder_model/conv2d_64/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_64/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_64/Relu:0 = Relu(%model/encoder_model/batch_normalization_64/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_65/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_64/Relu:0, %model/encoder_model/conv2d_65/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_65/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_65/Relu:0 = Relu(%model/encoder_model/batch_normalization_65/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_61/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_8_ac/Relu:0, %model/encoder_model/conv2d_61/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_61/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_61/Relu:0 = Relu(%model/encoder_model/batch_normalization_61/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_62/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_61/Relu:0, %model/encoder_model/conv2d_62/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_62/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_62/Relu:0 = Relu(%model/encoder_model/batch_normalization_62/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_60/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_8_ac/Relu:0, %model/encoder_model/conv2d_60/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_60/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_60/Relu:0 = Relu(%model/encoder_model/batch_normalization_60/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_9_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_60/Relu:0, %model/encoder_model/activation_62/Relu:0, %model/encoder_model/activation_65/Relu:0)\n",
      "  %model/encoder_model/block35_9_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_9_mixed/concat:0, %model/encoder_model/block35_9_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_9_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_9/mul:0 = Mul(%model/encoder_model/block35_9_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_9/add:0 = Add(%model/encoder_model/block35_8_ac/Relu:0, %model/encoder_model/block35_9/mul:0)\n",
      "  %model/encoder_model/block35_9_ac/Relu:0 = Relu(%model/encoder_model/block35_9/add:0)\n",
      "  %model/encoder_model/batch_normalization_69/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_9_ac/Relu:0, %model/encoder_model/conv2d_69/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_69/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_69/Relu:0 = Relu(%model/encoder_model/batch_normalization_69/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_70/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_69/Relu:0, %model/encoder_model/conv2d_70/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_70/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_70/Relu:0 = Relu(%model/encoder_model/batch_normalization_70/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_71/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_70/Relu:0, %model/encoder_model/conv2d_71/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_71/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_71/Relu:0 = Relu(%model/encoder_model/batch_normalization_71/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_67/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_9_ac/Relu:0, %model/encoder_model/conv2d_67/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_67/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_67/Relu:0 = Relu(%model/encoder_model/batch_normalization_67/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_68/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_67/Relu:0, %model/encoder_model/conv2d_68/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_68/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_68/Relu:0 = Relu(%model/encoder_model/batch_normalization_68/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_66/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_9_ac/Relu:0, %model/encoder_model/conv2d_66/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_66/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_66/Relu:0 = Relu(%model/encoder_model/batch_normalization_66/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block35_10_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_66/Relu:0, %model/encoder_model/activation_68/Relu:0, %model/encoder_model/activation_71/Relu:0)\n",
      "  %model/encoder_model/block35_10_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_10_mixed/concat:0, %model/encoder_model/block35_10_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block35_10_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block35_10/mul:0 = Mul(%model/encoder_model/block35_10_conv/BiasAdd:0, %model/encoder_model/block35_5/mul/y:0)\n",
      "  %model/encoder_model/block35_10/add:0 = Add(%model/encoder_model/block35_9_ac/Relu:0, %model/encoder_model/block35_10/mul:0)\n",
      "  %model/encoder_model/block35_10_ac/Relu:0 = Relu(%model/encoder_model/block35_10/add:0)\n",
      "  %model/encoder_model/max_pooling2d_2/MaxPool:0 = MaxPool[kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/block35_10_ac/Relu:0)\n",
      "  %model/encoder_model/batch_normalization_73/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block35_10_ac/Relu:0, %model/encoder_model/conv2d_73/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_73/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_73/Relu:0 = Relu(%model/encoder_model/batch_normalization_73/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_74/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%model/encoder_model/activation_73/Relu:0, %model/encoder_model/conv2d_74/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_74/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_74/Relu:0 = Relu(%model/encoder_model/batch_normalization_74/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_75/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/activation_74/Relu:0, %model/encoder_model/conv2d_75/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_75/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_75/Relu:0 = Relu(%model/encoder_model/batch_normalization_75/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_72/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], strides = [2, 2]](%model/encoder_model/block35_10_ac/Relu:0, %model/encoder_model/conv2d_72/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_72/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_72/Relu:0 = Relu(%model/encoder_model/batch_normalization_72/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/mixed_6a/concat:0 = Concat[axis = 1](%model/encoder_model/activation_72/Relu:0, %model/encoder_model/activation_75/Relu:0, %model/encoder_model/max_pooling2d_2/MaxPool:0)\n",
      "  %model/encoder_model/batch_normalization_77/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/mixed_6a/concat:0, %model/encoder_model/conv2d_77/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_77/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_77/Relu:0 = Relu(%model/encoder_model/batch_normalization_77/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_78/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_77/Relu:0, %model/encoder_model/conv2d_78/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_78/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_78/Relu:0 = Relu(%model/encoder_model/batch_normalization_78/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_79/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_78/Relu:0, %model/encoder_model/conv2d_79/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_79/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_79/Relu:0 = Relu(%model/encoder_model/batch_normalization_79/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_76/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/mixed_6a/concat:0, %model/encoder_model/conv2d_76/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_76/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_76/Relu:0 = Relu(%model/encoder_model/batch_normalization_76/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_1_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_76/Relu:0, %model/encoder_model/activation_79/Relu:0)\n",
      "  %model/encoder_model/block17_1_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_1_mixed/concat:0, %model/encoder_model/block17_1_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_1_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_1/mul:0 = Mul(%model/encoder_model/block17_1_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_1/add:0 = Add(%model/encoder_model/mixed_6a/concat:0, %model/encoder_model/block17_1/mul:0)\n",
      "  %model/encoder_model/block17_1_ac/Relu:0 = Relu(%model/encoder_model/block17_1/add:0)\n",
      "  %model/encoder_model/batch_normalization_81/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_1_ac/Relu:0, %model/encoder_model/conv2d_81/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_81/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_81/Relu:0 = Relu(%model/encoder_model/batch_normalization_81/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_82/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_81/Relu:0, %model/encoder_model/conv2d_82/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_82/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_82/Relu:0 = Relu(%model/encoder_model/batch_normalization_82/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_83/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_82/Relu:0, %model/encoder_model/conv2d_83/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_83/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_83/Relu:0 = Relu(%model/encoder_model/batch_normalization_83/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_80/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_1_ac/Relu:0, %model/encoder_model/conv2d_80/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_80/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_80/Relu:0 = Relu(%model/encoder_model/batch_normalization_80/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_2_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_80/Relu:0, %model/encoder_model/activation_83/Relu:0)\n",
      "  %model/encoder_model/block17_2_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_2_mixed/concat:0, %model/encoder_model/block17_2_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_2_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_2/mul:0 = Mul(%model/encoder_model/block17_2_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_2/add:0 = Add(%model/encoder_model/block17_1_ac/Relu:0, %model/encoder_model/block17_2/mul:0)\n",
      "  %model/encoder_model/block17_2_ac/Relu:0 = Relu(%model/encoder_model/block17_2/add:0)\n",
      "  %model/encoder_model/batch_normalization_85/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_2_ac/Relu:0, %model/encoder_model/conv2d_85/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_85/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_85/Relu:0 = Relu(%model/encoder_model/batch_normalization_85/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_86/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_85/Relu:0, %model/encoder_model/conv2d_86/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_86/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_86/Relu:0 = Relu(%model/encoder_model/batch_normalization_86/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_87/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_86/Relu:0, %model/encoder_model/conv2d_87/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_87/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_87/Relu:0 = Relu(%model/encoder_model/batch_normalization_87/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_84/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_2_ac/Relu:0, %model/encoder_model/conv2d_84/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_84/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_84/Relu:0 = Relu(%model/encoder_model/batch_normalization_84/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_3_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_84/Relu:0, %model/encoder_model/activation_87/Relu:0)\n",
      "  %model/encoder_model/block17_3_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_3_mixed/concat:0, %model/encoder_model/block17_3_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_3_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_3/mul:0 = Mul(%model/encoder_model/block17_3_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_3/add:0 = Add(%model/encoder_model/block17_2_ac/Relu:0, %model/encoder_model/block17_3/mul:0)\n",
      "  %model/encoder_model/block17_3_ac/Relu:0 = Relu(%model/encoder_model/block17_3/add:0)\n",
      "  %model/encoder_model/batch_normalization_89/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_3_ac/Relu:0, %model/encoder_model/conv2d_89/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_89/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_89/Relu:0 = Relu(%model/encoder_model/batch_normalization_89/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_90/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_89/Relu:0, %model/encoder_model/conv2d_90/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_90/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_90/Relu:0 = Relu(%model/encoder_model/batch_normalization_90/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_91/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_90/Relu:0, %model/encoder_model/conv2d_91/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_91/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_91/Relu:0 = Relu(%model/encoder_model/batch_normalization_91/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_88/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_3_ac/Relu:0, %model/encoder_model/conv2d_88/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_88/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_88/Relu:0 = Relu(%model/encoder_model/batch_normalization_88/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_4_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_88/Relu:0, %model/encoder_model/activation_91/Relu:0)\n",
      "  %model/encoder_model/block17_4_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_4_mixed/concat:0, %model/encoder_model/block17_4_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_4_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_4/mul:0 = Mul(%model/encoder_model/block17_4_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_4/add:0 = Add(%model/encoder_model/block17_3_ac/Relu:0, %model/encoder_model/block17_4/mul:0)\n",
      "  %model/encoder_model/block17_4_ac/Relu:0 = Relu(%model/encoder_model/block17_4/add:0)\n",
      "  %model/encoder_model/batch_normalization_93/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_4_ac/Relu:0, %model/encoder_model/conv2d_93/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_93/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_93/Relu:0 = Relu(%model/encoder_model/batch_normalization_93/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_94/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_93/Relu:0, %model/encoder_model/conv2d_94/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_94/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_94/Relu:0 = Relu(%model/encoder_model/batch_normalization_94/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_95/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_94/Relu:0, %model/encoder_model/conv2d_95/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_95/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_95/Relu:0 = Relu(%model/encoder_model/batch_normalization_95/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_92/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_4_ac/Relu:0, %model/encoder_model/conv2d_92/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_92/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_92/Relu:0 = Relu(%model/encoder_model/batch_normalization_92/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_5_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_92/Relu:0, %model/encoder_model/activation_95/Relu:0)\n",
      "  %model/encoder_model/block17_5_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_5_mixed/concat:0, %model/encoder_model/block17_5_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_5_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_5/mul:0 = Mul(%model/encoder_model/block17_5_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_5/add:0 = Add(%model/encoder_model/block17_4_ac/Relu:0, %model/encoder_model/block17_5/mul:0)\n",
      "  %model/encoder_model/block17_5_ac/Relu:0 = Relu(%model/encoder_model/block17_5/add:0)\n",
      "  %model/encoder_model/batch_normalization_97/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_5_ac/Relu:0, %model/encoder_model/conv2d_97/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_97/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_97/Relu:0 = Relu(%model/encoder_model/batch_normalization_97/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_98/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_97/Relu:0, %model/encoder_model/conv2d_98/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_98/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_98/Relu:0 = Relu(%model/encoder_model/batch_normalization_98/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_99/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_98/Relu:0, %model/encoder_model/conv2d_99/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_99/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_99/Relu:0 = Relu(%model/encoder_model/batch_normalization_99/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_96/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_5_ac/Relu:0, %model/encoder_model/conv2d_96/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_96/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_96/Relu:0 = Relu(%model/encoder_model/batch_normalization_96/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_6_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_96/Relu:0, %model/encoder_model/activation_99/Relu:0)\n",
      "  %model/encoder_model/block17_6_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_6_mixed/concat:0, %model/encoder_model/block17_6_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_6_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_6/mul:0 = Mul(%model/encoder_model/block17_6_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_6/add:0 = Add(%model/encoder_model/block17_5_ac/Relu:0, %model/encoder_model/block17_6/mul:0)\n",
      "  %model/encoder_model/block17_6_ac/Relu:0 = Relu(%model/encoder_model/block17_6/add:0)\n",
      "  %model/encoder_model/batch_normalization_101/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_6_ac/Relu:0, %model/encoder_model/conv2d_101/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_101/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_101/Relu:0 = Relu(%model/encoder_model/batch_normalization_101/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_102/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_101/Relu:0, %model/encoder_model/conv2d_102/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_102/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_102/Relu:0 = Relu(%model/encoder_model/batch_normalization_102/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_103/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_102/Relu:0, %model/encoder_model/conv2d_103/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_103/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_103/Relu:0 = Relu(%model/encoder_model/batch_normalization_103/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_100/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_6_ac/Relu:0, %model/encoder_model/conv2d_100/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_100/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_100/Relu:0 = Relu(%model/encoder_model/batch_normalization_100/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_7_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_100/Relu:0, %model/encoder_model/activation_103/Relu:0)\n",
      "  %model/encoder_model/block17_7_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_7_mixed/concat:0, %model/encoder_model/block17_7_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_7_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_7/mul:0 = Mul(%model/encoder_model/block17_7_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_7/add:0 = Add(%model/encoder_model/block17_6_ac/Relu:0, %model/encoder_model/block17_7/mul:0)\n",
      "  %model/encoder_model/block17_7_ac/Relu:0 = Relu(%model/encoder_model/block17_7/add:0)\n",
      "  %model/encoder_model/batch_normalization_105/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_7_ac/Relu:0, %model/encoder_model/conv2d_105/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_105/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_105/Relu:0 = Relu(%model/encoder_model/batch_normalization_105/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_106/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 7], pads = [0, 3, 0, 3], strides = [1, 1]](%model/encoder_model/activation_105/Relu:0, %model/encoder_model/conv2d_106/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_106/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_106/Relu:0 = Relu(%model/encoder_model/batch_normalization_106/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_107/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 1], pads = [3, 0, 3, 0], strides = [1, 1]](%model/encoder_model/activation_106/Relu:0, %model/encoder_model/conv2d_107/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_107/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_107/Relu:0 = Relu(%model/encoder_model/batch_normalization_107/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/batch_normalization_104/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_7_ac/Relu:0, %model/encoder_model/conv2d_104/Conv2D_weights_fused_bn, %model/encoder_model/conv2d_104/Conv2D_bias_fused_bn)\n",
      "  %model/encoder_model/activation_104/Relu:0 = Relu(%model/encoder_model/batch_normalization_104/FusedBatchNormV3:0)\n",
      "  %model/encoder_model/block17_8_mixed/concat:0 = Concat[axis = 1](%model/encoder_model/activation_104/Relu:0, %model/encoder_model/activation_107/Relu:0)\n",
      "  %model/encoder_model/block17_8_conv/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%model/encoder_model/block17_8_mixed/concat:0, %model/encoder_model/block17_8_conv/Conv2D/ReadVariableOp:0, %model/encoder_model/block17_8_conv/BiasAdd/ReadVariableOp:0)\n",
      "  %model/encoder_model/block17_8/mul:0 = Mul(%model/encoder_model/block17_8_conv/BiasAdd:0, %model/encoder_model/block17_3/mul/y:0)\n",
      "  %model/encoder_model/block17_8/add:0 = Add(%model/encoder_model/block17_7_ac/Relu:0, %model/encoder_model/block17_8/mul:0)\n",
      "  %model/encoder_model/block17_8_ac/Relu:0 = Relu(%model/encoder_model/block17_8/add:0)\n",
      "  %model/global_average_pooling2d/Mean:0 = GlobalAveragePool(%model/encoder_model/block17_8_ac/Relu:0)\n",
      "  %model/global_average_pooling2d/Mean_Squeeze__5452:0 = Squeeze(%model/global_average_pooling2d/Mean:0, %const_axes__5451)\n",
      "  %model/dense/MatMul:0 = MatMul(%model/global_average_pooling2d/Mean_Squeeze__5452:0, %model/dense/MatMul/ReadVariableOp:0)\n",
      "  %dense = Softmax(%model/dense/MatMul:0)\n",
      "  return %dense\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Verify the model\n",
    "#\n",
    "import onnx\n",
    "onnx_model_path = \"/notebooks/my_model.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:32.615755Z",
     "iopub.status.busy": "2024-01-26T03:11:32.615510Z",
     "iopub.status.idle": "2024-01-26T03:11:33.962054Z",
     "shell.execute_reply": "2024-01-26T03:11:33.960953Z",
     "shell.execute_reply.started": "2024-01-26T03:11:32.615733Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Set up the split of Augmented images 50/50 as required of binary cross entropy\n",
    "# Warning: Do not run this multiple times. \n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(combinedImages, combinedYlabel, test_size=0.50, random_state=1)\n",
    "\n",
    "# Set up what appears to be a confusion matrix?\n",
    "# Required for binary cross\n",
    "from keras.utils import to_categorical\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train =to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:33.964731Z",
     "iopub.status.busy": "2024-01-26T03:11:33.963908Z",
     "iopub.status.idle": "2024-01-26T03:11:33.973741Z",
     "shell.execute_reply": "2024-01-26T03:11:33.972510Z",
     "shell.execute_reply.started": "2024-01-26T03:11:33.964664Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler,EarlyStopping\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.000145  # Initial learning rate\n",
    "    drop = 0.065     # Amount to drop the learning rate\n",
    "    epochs_drop = 15   # Number of epochs after which to drop the learning rate\n",
    "\n",
    "    lr = initial_lr * (1 / (1 + drop * epoch / epochs_drop))\n",
    "\n",
    "    return lr\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=15,           \n",
    "    restore_best_weights=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:33.975671Z",
     "iopub.status.busy": "2024-01-26T03:11:33.975158Z",
     "iopub.status.idle": "2024-01-26T03:11:34.015451Z",
     "shell.execute_reply": "2024-01-26T03:11:34.014131Z",
     "shell.execute_reply.started": "2024-01-26T03:11:33.975648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 299, 299, 1)]     0         \n",
      "                                                                 \n",
      " encoder_model (Functional)  (None, 17, 17, 1088)      13361888  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1088)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1088)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2178      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,364,066\n",
      "Trainable params: 12,023,026\n",
      "Non-trainable params: 1,341,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:34.020008Z",
     "iopub.status.busy": "2024-01-26T03:11:34.018728Z",
     "iopub.status.idle": "2024-01-26T03:11:34.023865Z",
     "shell.execute_reply": "2024-01-26T03:11:34.022992Z",
     "shell.execute_reply.started": "2024-01-26T03:11:34.019940Z"
    }
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#tf.keras.applications.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:34.025067Z",
     "iopub.status.busy": "2024-01-26T03:11:34.024790Z",
     "iopub.status.idle": "2024-01-26T03:11:34.047845Z",
     "shell.execute_reply": "2024-01-26T03:11:34.046716Z",
     "shell.execute_reply.started": "2024-01-26T03:11:34.025046Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "classification_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.000145), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:11:34.050004Z",
     "iopub.status.busy": "2024-01-26T03:11:34.049701Z",
     "iopub.status.idle": "2024-01-26T03:20:41.665013Z",
     "shell.execute_reply": "2024-01-26T03:20:41.663991Z",
     "shell.execute_reply.started": "2024-01-26T03:11:34.049982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 36s 603ms/step - loss: 0.6170 - accuracy: 0.6366 - val_loss: 0.5821 - val_accuracy: 0.6681 - lr: 1.4500e-04\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.4914 - accuracy: 0.7461 - val_loss: 0.5192 - val_accuracy: 0.7055 - lr: 1.4437e-04\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 0.4000 - accuracy: 0.7948 - val_loss: 0.5776 - val_accuracy: 0.7296 - lr: 1.4375e-04\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 0.3048 - accuracy: 0.8658 - val_loss: 0.8734 - val_accuracy: 0.7381 - lr: 1.4314e-04\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 18s 470ms/step - loss: 0.1586 - accuracy: 0.9498 - val_loss: 0.6318 - val_accuracy: 0.7814 - lr: 1.4253e-04\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 18s 471ms/step - loss: 0.0699 - accuracy: 0.9802 - val_loss: 0.5808 - val_accuracy: 0.8215 - lr: 1.4192e-04\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0468 - accuracy: 0.9888 - val_loss: 1.8787 - val_accuracy: 0.6937 - lr: 1.4133e-04\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 3.1536 - val_accuracy: 0.6873 - lr: 1.4073e-04\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 1.8750 - val_accuracy: 0.7173 - lr: 1.4014e-04\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 0.0552 - accuracy: 0.9818 - val_loss: 0.4290 - val_accuracy: 0.8797 - lr: 1.3956e-04\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 18s 467ms/step - loss: 0.0190 - accuracy: 0.9979 - val_loss: 1.0215 - val_accuracy: 0.7552 - lr: 1.3898e-04\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.8301 - val_accuracy: 0.8236 - lr: 1.3840e-04\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.7711 - val_accuracy: 0.8418 - lr: 1.3783e-04\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 18s 471ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.4637 - val_accuracy: 0.8899 - lr: 1.3727e-04\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.9280 - val_accuracy: 0.8177 - lr: 1.3671e-04\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8899 - lr: 1.3615e-04\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 22s 598ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8813 - lr: 1.3560e-04\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8749 - lr: 1.3505e-04\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 18s 467ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.8824 - lr: 1.3451e-04\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 22s 599ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.8696 - lr: 1.3397e-04\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.8642 - lr: 1.3344e-04\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 4.6554 - val_accuracy: 0.8348 - lr: 1.3291e-04\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 0.8666 - val_accuracy: 0.8279 - lr: 1.3238e-04\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 18s 467ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8707 - lr: 1.3186e-04\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 18s 467ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7382 - val_accuracy: 0.8520 - lr: 1.3134e-04\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 18s 466ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.8797 - lr: 1.3083e-04\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 22s 598ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5774 - val_accuracy: 0.8840 - lr: 1.3032e-04\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 18s 467ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8803 - lr: 1.2981e-04\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 18s 471ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 1.6337 - val_accuracy: 0.7531 - lr: 1.2931e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0dd8027250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X_train, y_train, epochs=100, batch_size=50, callbacks=[lr_scheduler,early_stopping], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:20:41.667066Z",
     "iopub.status.busy": "2024-01-26T03:20:41.666379Z",
     "iopub.status.idle": "2024-01-26T03:20:41.911791Z",
     "shell.execute_reply": "2024-01-26T03:20:41.911000Z",
     "shell.execute_reply.started": "2024-01-26T03:20:41.667040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #\n",
    "    # Results of the classification\n",
    "    # \n",
    "    plt.plot(classification_model.history.history['loss'], label='training Loss')\n",
    "    plt.plot(classification_model.history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:20:41.915669Z",
     "iopub.status.busy": "2024-01-26T03:20:41.915142Z",
     "iopub.status.idle": "2024-01-26T03:20:42.072447Z",
     "shell.execute_reply": "2024-01-26T03:20:42.071743Z",
     "shell.execute_reply.started": "2024-01-26T03:20:41.915643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.plot(classification_model.history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(classification_model.history.history['val_accuracy'], label='val_accuracy')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Acc Curves')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:20:42.073649Z",
     "iopub.status.busy": "2024-01-26T03:20:42.073419Z",
     "iopub.status.idle": "2024-01-26T03:21:02.678580Z",
     "shell.execute_reply": "2024-01-26T03:21:02.677623Z",
     "shell.execute_reply.started": "2024-01-26T03:20:42.073627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 10s 100ms/step\n",
      "39/39 [==============================] - 4s 115ms/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combinedImages , combinedYlabel, test_size=0.33, random_state=1)\n",
    "\n",
    "X_train_encode = classification_model.predict(X_train)\n",
    "X_test_encode = classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T03:54:16.028641Z",
     "iopub.status.busy": "2024-01-26T03:54:16.026334Z",
     "iopub.status.idle": "2024-01-26T03:54:16.057108Z",
     "shell.execute_reply": "2024-01-26T03:54:16.056320Z",
     "shell.execute_reply.started": "2024-01-26T03:54:16.028607Z"
    }
   },
   "outputs": [],
   "source": [
    "#In order to keep the dataset the same for the model loader\n",
    "np.save('X_train_encode_model_Example.npy', X_train_encode)\n",
    "np.save('X_test_encode_model_Example.npy', X_test_encode)\n",
    "np.save('y_train_example.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
